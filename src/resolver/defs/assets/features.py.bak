import os
from pathlib import Path
from dagster import asset, AssetExecutionContext, MaterializeResult, MetadataValue
from typing import List
import duckdb as duckdblib
from resolver.defs.resources import DuckDBResource
from resolver.defs.sql_utils import render_sql

SHARD_MODULUS = int(os.getenv("SHARD_MODULUS", "64"))
PAIRS_TABLE = "er.blocking_pairs"
COMPANIES_TABLE = "silver.companies"
OUT_DIR = Path("data/er/pair_features_shards")


def make_feature_shard_asset(i: int):

  @asset(name=f"er_pair_features_shard_{i}",
         deps=["er_blocking_pairs"],
         group_name="internal/shards")
  def er_pair_features_shard_i(context: AssetExecutionContext,
                               duckdb: DuckDBResource) -> MaterializeResult:
    OUT_DIR.mkdir(parents=True, exist_ok=True)
    out_path = OUT_DIR / f"shard={i}.parquet"

    sql = render_sql(
      "pair_features_shard.sql.j2",
      shard_index=i,
      shard_modulus=SHARD_MODULUS,
      pairs_table=PAIRS_TABLE,
      companies_table=COMPANIES_TABLE,
    )
    # our rendered sql is standalone (ends with ';')
    # but in this asset, we are embedding it in a COPY
    # so we need to get rid of that semi-colon
    inner = sql.rstrip().rstrip(';').rstrip()
    # Read-only DB access; write features as Parquet to avoid file locks
    try:
      con = duckdblib.connect(os.getenv("DUCKDB_DATABASE"), read_only=True)
      con.execute("PRAGMA threads=2")
      con.execute("PRAGMA memory_limit='4GB'")
      con.execute("PRAGMA temp_directory='/tmp/duckdb-temp'")

      # Export directly from SELECT to Parquet (no table creation needed)
      con.execute(f"""
                COPY (
                    {inner}
                ) TO '{out_path.as_posix()}'
                (FORMAT PARQUET, OVERWRITE_OR_IGNORE TRUE);
            """)
      # count rows for metadata
      cnt = con.execute(
        f"SELECT COUNT(*) FROM read_parquet('{out_path.as_posix()}')").fetchone()[0]

      return MaterializeResult(
        metadata={
          "shard": MetadataValue.int(i),
          "rows": MetadataValue.int(cnt),
          "parquet": MetadataValue.path(out_path.as_posix()),
        })

    finally:
      con.close()

  return er_pair_features_shard_i


feature_shard_assets: List = [make_feature_shard_asset(i) for i in range(SHARD_MODULUS)]


@asset(deps=feature_shard_assets, name="er_pair_features")
def er_pair_features_union(context: AssetExecutionContext,
                           duckdb: DuckDBResource) -> MaterializeResult:
  """Single-writer step: union all shard Parquet into a DuckDB table."""
  with duckdb.get_connection() as con:
    con.execute("PRAGMA threads=4")
    con.execute("PRAGMA temp_directory='/tmp/duckdb-temp'")
    con.execute("""
            CREATE SCHEMA IF NOT EXISTS er;
            CREATE OR REPLACE TABLE er.pair_features AS
            SELECT *
            FROM read_parquet('data/er/pair_features_shards/shard=*.parquet');
        """)
    total = con.execute("SELECT COUNT(*) FROM er.pair_features").fetchone()[0]

    # quick feature sanity: how many exact domain matches?
    dom = con.execute("""
            SELECT SUM(domain_exact) AS domain_exact_matches
            FROM er.pair_features
        """).fetchone()[0]

  return MaterializeResult(
    metadata={
      "total_rows": MetadataValue.int(total),
      "domain_exact_matches": MetadataValue.int(int(dom or 0)),
      "source_pairs": MetadataValue.text(PAIRS_TABLE),
    })
