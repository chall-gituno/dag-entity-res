# src/resolver/defs/assets/features_nofanout.py
import os
from __future__ import annotations
from dagster import asset, AssetExecutionContext, MaterializeResult, MetadataValue
from pathlib import Path
import duckdb as duckdblib
from resolver.defs.resources import DuckDBResource
from typing import Iterable
from resolver.defs.sql_utils import render_sql

SHARD_MODULUS = int(os.getenv("SHARD_MODULUS", "64"))
OUT_DIR_DEFAULT = Path("data/er/pair_features_shards")


def _strip_for_copy(sql: str) -> str:
  return sql.rstrip().rstrip(";").rstrip()


def _iter_shards(modulus: int, only: Iterable[int] | None) -> Iterable[int]:
  if only:
    for i in only:
      yield i
  else:
    for i in range(modulus):
      yield i


@asset(name="er_pair_features", group_name="er")
def er_pair_features(context: AssetExecutionContext,
                     duckdb: DuckDBResource) -> MaterializeResult:
  """
    Monolithic asset: generates per-shard Parquet features (read-only)
    and then unions them into er.pair_features (single-writer).
    """

  # ---- config knobs (optional in run config) ----
  cfg = (context.op_execution_context.run_config or {})
  # legacy/run_config mapping: try both roots
  cfg_assets = cfg.get("assets", {}).get("er_pair_features", {})
  cfg_ops = cfg.get("ops", {}).get("er_pair_features", {})
  cfg = {**cfg_ops, **cfg_assets}

  shard_modulus: int = int(cfg.get("shard_modulus", SHARD_MODULUS))
  only_shards: list[int] = cfg.get("only_shards", [])  # e.g. [0,1] for dev
  overwrite: bool = bool(cfg.get("overwrite", False))
  out_dir = Path(cfg.get("out_dir", OUT_DIR_DEFAULT))

  # source tables
  pairs_table = cfg.get("pairs_table", "er.blocking_pairs")
  companies_table = cfg.get("companies_table", "silver.companies")

  # database path(s)
  # Use env or your resource config instead if you prefer
  db_path = cfg.get("database", os.getenv("DUCKDB_DATABASE"))

  out_dir.mkdir(parents=True, exist_ok=True)

  # ---- Phase 1: generate shard Parquet sequentially (read-only) ----
  produced = 0
  rows_total = 0
  shard_rows: list[tuple[int, int]] = []

  for i in _iter_shards(shard_modulus, only_shards):
    out_path = out_dir / f"shard={i}.parquet"
    if out_path.exists() and not overwrite:
      # Count rows for metadata (fast path)
      cnt = duckdb.connect(read_only=True).execute(
        f"SELECT COUNT(*) FROM read_parquet('{out_path.as_posix()}')").fetchone()[0]
      shard_rows.append((i, cnt))
      rows_total += cnt
      continue

    sql = render_sql(
      "pair_features_shard.sql.j2",
      shard_index=i,
      shard_modulus=shard_modulus,
      pairs_table=pairs_table,
      companies_table=companies_table,
    )
    inner = _strip_for_copy(sql)

    # Read-only connection per shard
    con_ro = duckdblib.connect(db_path, read_only=True)
    try:
      con_ro.execute("PRAGMA temp_directory='/tmp/duckdb-temp'")
      con_ro.execute("PRAGMA memory_limit='4GB'")
      con_ro.execute("PRAGMA threads=2")
      con_ro.execute(f"""
                COPY (
                    {inner}
                ) TO '{out_path.as_posix()}'
                (FORMAT PARQUET, OVERWRITE_OR_IGNORE {'TRUE' if overwrite else 'FALSE'});
            """)
      cnt = con_ro.execute(
        f"SELECT COUNT(*) FROM read_parquet('{out_path.as_posix()}')").fetchone()[0]
    finally:
      con_ro.close()

    produced += 1
    shard_rows.append((i, cnt))
    rows_total += cnt
    # (optional) emit a tiny log line
    context.log.info(f"Shard {i}: {cnt} rows → {out_path}")

  # ---- Phase 2: single-writer union → DuckDB table ----
  con = duckdb.connect(db_path)
  try:
    con.execute("PRAGMA temp_directory='/tmp/duckdb-temp'")
    con.execute("PRAGMA memory_limit='6GB'")
    con.execute("PRAGMA threads=4")
    con.execute(
      """
            CREATE SCHEMA IF NOT EXISTS er;
            CREATE OR REPLACE TABLE er.pair_features AS
            SELECT * FROM read_parquet($parquet_glob);
        """, {"parquet_glob": str(out_dir / "shard=*.parquet")})
    total = con.execute("SELECT COUNT(*) FROM er.pair_features").fetchone()[0]
  finally:
    con.close()

  # ---- MaterializeResult metadata ----
  shard_meta = [{"shard": i, "rows": r} for (i, r) in shard_rows]
  return MaterializeResult(
    metadata={
      "shards_produced_now": MetadataValue.int(produced),
      "rows_in_parquet_sum": MetadataValue.int(rows_total),
      "rows_in_union_table": MetadataValue.int(total),
      "shard_modulus": MetadataValue.int(shard_modulus),
      "parquet_dir": MetadataValue.path(out_dir.as_posix()),
      "sample_shards": MetadataValue.json(shard_meta[:10]),
    })
