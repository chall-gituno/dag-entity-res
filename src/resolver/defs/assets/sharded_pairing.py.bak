import os
from pathlib import Path
import dagster as dg
#from dagster import asset, AssetExecutionContext, MaterializeResult, MetadataValue
from typing import List
from resolver.defs.resources import DuckDBResource
from resolver.defs.sql_utils import render_sql
from resolver.defs.settings import ERSettings

SHARD_MODULUS = int(os.getenv("SHARD_MODULUS", "64"))

CAP_PER_A = None  # e.g. 200 to cap; None = no cap
OUT_DIR = Path("/tmp/data/er/blocking_pairs_shards")  # per-shard files


def make_pairs_shard(i: int, duckdb, settings: ERSettings):
  # DuckDB can only have one process writing to the .duckdb at a time
  # To avoid locking conflicts, we'll write shards to parquet and then
  # union them all as a single write
  OUT_DIR.mkdir(parents=True, exist_ok=True)
  out_path = OUT_DIR / f"shard={i}.parquet"

  #pairs_shard_table = f"ephem.blocking_pairs_shard_{i}"
  # setting shard table to none will mean we won't create it
  # assumes we are not wanting them around for later inspection
  pairs_shard_table = None
  sql = render_sql(
    "blocking_pairs_shard.sql.j2",
    blocks_table=settings.blocks_table,
    shard_table=pairs_shard_table,
    shard_index=i,
    shard_modulus=SHARD_MODULUS,
    cap_per_a=CAP_PER_A,
    #bkey_hash_col='bkey_hash',
  )

  inner = sql.rstrip().rstrip(';').rstrip()
  with duckdb.get_connection() as con:
    con.execute("PRAGMA temp_directory='/tmp/duckdb-temp'")
    if pairs_shard_table:
      # create ephemeral schema if we are keeping tables
      con.execute("CREATE SCHEMA IF NOT EXISTS ephem")
    exec_comm = f"""
          COPY (
              {inner}
          ) TO '{out_path.as_posix()}'
          (FORMAT PARQUET, OVERWRITE_OR_IGNORE TRUE);
      """
    #
    con.execute(exec_comm)
    # if you wanna keep shards in the database for inspection
    # you can use the following.
    # con.execute(sql)
    # con.execute(f"""
    #       COPY (SELECT * FROM {pairs_shard_table})
    #       TO '{out_path.as_posix()}'
    #       (FORMAT PARQUET, OVERWRITE_OR_IGNORE TRUE);
    #   """)
  return out_path.as_posix()
  #return pairs_shard_table


def cleanup_this_mess(duckdb):
  """If you persisted shards to the DB, you can call this to clean em out"""
  with duckdb.get_connection() as conn:
    conn.execute("DROP SCHEMA IF EXISTS ephem CASCADE")


@dg.asset(
  name="er_company_blocking_pairs",
  deps=["er_company_blocking"],
  group_name="er",
  tags={"quality": "working"},
)
def er_company_blocking_pairs(context, duckdb: DuckDBResource, settings: ERSettings):
  """
  Create our pairs table.  This will use a sharding approach to keep memory flat.
  """
  pair_shards: List = [
    make_pairs_shard(i, duckdb, settings) for i in range(SHARD_MODULUS)
  ]

  out_table = settings.pairs_table
  with duckdb.get_connection() as con:
    con.execute(f"""
            CREATE OR REPLACE TABLE {out_table} AS
            SELECT distinct * FROM read_parquet('{OUT_DIR}/shard=*.parquet');
        """)
    total = con.execute(f"SELECT COUNT(*) FROM {out_table}").fetchone()[0]

  outcome = {
    "rows": total,
    "total_shards": len(pair_shards),
    "ouput_table": out_table,
  }
  cleanup_this_mess(duckdb)
  context.add_output_metadata(outcome)
