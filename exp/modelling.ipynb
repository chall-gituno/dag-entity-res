{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3652d5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# Use this line to ignore the specific UserWarning message\n",
    "warnings.filterwarnings(\n",
    "    action='ignore',\n",
    "    message='pandas only supports SQLAlchemy',\n",
    "    category=UserWarning\n",
    ")\n",
    "\n",
    "def load_sample_data(table_name, sample_size=1000):\n",
    "    \"\"\"\n",
    "    Loads a sample of data from a DuckDB table into a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        table_name (str): The name of the table to sample from.\n",
    "        sample_size (int): The number of rows to sample.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the sample data.\n",
    "    \"\"\"\n",
    "    # 1. Establish a connection to the DuckDB database file\n",
    "    # Using ':memory:' for a temporary in-memory database\n",
    "    # Replace with 'path/to/your/database.duckdb' to connect to a file\n",
    "    with duckdb.connect(database='/opt/test-data/experimental.duckdb', read_only=True) as conn:\n",
    "        try:\n",
    "            # 2. Use a SQL query to select a sample\n",
    "            query = f\"SELECT * FROM {table_name} using sample {sample_size} rows\"\n",
    "\n",
    "            # 3. Use pandas.read_sql to execute the query and load the data\n",
    "            df = pd.read_sql(query, conn)\n",
    "            \n",
    "            print(f\"Successfully loaded a sample of {len(df)} rows from {table_name}.\")\n",
    "            return df\n",
    "        \n",
    "        except duckdb.Error as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9341a02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded a sample of 20000 rows from er.pair_features.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_id_a</th>\n",
       "      <th>company_id_b</th>\n",
       "      <th>domain_exact</th>\n",
       "      <th>country_exact</th>\n",
       "      <th>city_exact</th>\n",
       "      <th>name_exact</th>\n",
       "      <th>name_compact_exact</th>\n",
       "      <th>name_prefix4_eq</th>\n",
       "      <th>name_prefix6_eq</th>\n",
       "      <th>emp_cur_absdiff</th>\n",
       "      <th>emp_cur_reldiff</th>\n",
       "      <th>emp_tot_absdiff</th>\n",
       "      <th>emp_tot_reldiff</th>\n",
       "      <th>both_have_domain</th>\n",
       "      <th>both_have_name</th>\n",
       "      <th>country_a</th>\n",
       "      <th>country_b</th>\n",
       "      <th>city_a</th>\n",
       "      <th>city_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3141475</td>\n",
       "      <td>3813168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>italy</td>\n",
       "      <td>italy</td>\n",
       "      <td>udine</td>\n",
       "      <td>milan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>385551</td>\n",
       "      <td>3218682</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>united states</td>\n",
       "      <td>united states</td>\n",
       "      <td>new york</td>\n",
       "      <td>hampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1178364</td>\n",
       "      <td>4420764</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>manchester</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>665884</td>\n",
       "      <td>4727305</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>united states</td>\n",
       "      <td>united states</td>\n",
       "      <td>parkersburg</td>\n",
       "      <td>grand rapids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>577274</td>\n",
       "      <td>3486868</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>myanmar</td>\n",
       "      <td>myanmar</td>\n",
       "      <td>mandalay</td>\n",
       "      <td>rangoon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   company_id_a  company_id_b  domain_exact  country_exact  city_exact  \\\n",
       "0       3141475       3813168             0            1.0         0.0   \n",
       "1        385551       3218682             0            1.0         0.0   \n",
       "2       1178364       4420764             0            1.0         NaN   \n",
       "3        665884       4727305             0            1.0         0.0   \n",
       "4        577274       3486868             0            1.0         0.0   \n",
       "\n",
       "   name_exact  name_compact_exact  name_prefix4_eq  name_prefix6_eq  \\\n",
       "0           0                   0                0                0   \n",
       "1           0                   0                1                1   \n",
       "2           0                   0                1                1   \n",
       "3           0                   0                1                1   \n",
       "4           0                   0                1                1   \n",
       "\n",
       "   emp_cur_absdiff  emp_cur_reldiff  emp_tot_absdiff  emp_tot_reldiff  \\\n",
       "0                2              0.4                3         0.300000   \n",
       "1                0              NaN                4         0.800000   \n",
       "2                3              1.0                4         0.800000   \n",
       "3               13              1.0               28         0.933333   \n",
       "4                5              1.0                5         0.833333   \n",
       "\n",
       "   both_have_domain  both_have_name       country_a       country_b  \\\n",
       "0                 1               1           italy           italy   \n",
       "1                 1               1   united states   united states   \n",
       "2                 1               1  united kingdom  united kingdom   \n",
       "3                 1               1   united states   united states   \n",
       "4                 1               1         myanmar         myanmar   \n",
       "\n",
       "        city_a        city_b  \n",
       "0        udine         milan  \n",
       "1     new york       hampton  \n",
       "2   manchester          None  \n",
       "3  parkersburg  grand rapids  \n",
       "4     mandalay       rangoon  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = load_sample_data(\"er.pair_features\",20000)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891be117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.993     0.996       423\n",
      "           1      0.994     1.000     0.997       525\n",
      "\n",
      "    accuracy                          0.997       948\n",
      "   macro avg      0.997     0.996     0.997       948\n",
      "weighted avg      0.997     0.997     0.997       948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load your pair_features (CSV or from DuckDB via .df())\n",
    "#df = pd.read_csv(\"pair_features_sample.csv\")\n",
    "# --- Weak labels ---\n",
    "pos_mask = (df[\"domain_exact\"] == 1) | (\n",
    "    (df[\"country_exact\"] == 1) &\n",
    "    (df[\"name_prefix6_eq\"] == 1) &\n",
    "    (df[\"emp_tot_reldiff\"].fillna(1.0) <= 0.20)\n",
    ")\n",
    "\n",
    "neg_mask = (df[\"country_exact\"] == 0) | (\n",
    "    (df[\"name_prefix4_eq\"] == 0) &\n",
    "    (df[\"emp_tot_reldiff\"].fillna(1.0) >= 0.90)\n",
    ")\n",
    "\n",
    "# remove overlaps: positives win ties\n",
    "neg_mask = neg_mask & (~pos_mask)\n",
    "\n",
    "pos = df[pos_mask].copy()\n",
    "pos[\"label\"] = 1\n",
    "neg = df[neg_mask].copy()\n",
    "neg[\"label\"] = 0\n",
    "\n",
    "# Optional: downsample negatives to balance\n",
    "neg_sample = neg.sample(n=min(len(pos), len(neg)), random_state=42)\n",
    "weak_train = pd.concat([pos, neg_sample], ignore_index=True).sample(frac=1, random_state=42)\n",
    "\n",
    "# --- Features / target ---\n",
    "drop_id_cols = [\"company_id_a\", \"company_id_b\"]\n",
    "X = weak_train.drop(columns=[\"label\"] + drop_id_cols, errors=\"ignore\")\n",
    "y = weak_train[\"label\"]\n",
    "\n",
    "# 2) Work out which categorical columns are actually present\n",
    "candidate_cat = [\"country_a\", \"country_b\", \"city_a\", \"city_b\"]\n",
    "cat_cols = [c for c in candidate_cat if c in X.columns]\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "# (Optional) quick sanity: see if anything is missing\n",
    "missing = set(cat_cols) - set(X.columns)\n",
    "assert not missing, f\"These categorical columns are missing from X: {missing}\"\n",
    "\n",
    "# 3) Preprocess: impute NaNs, one-hot the cats, pass through nums\n",
    "pre = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", make_pipeline(SimpleImputer(strategy=\"median\")), num_cols),\n",
    "        (\"cat\", make_pipeline(SimpleImputer(strategy=\"most_frequent\"),\n",
    "                              OneHotEncoder(handle_unknown=\"ignore\")), cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "# 4) Model\n",
    "clf = Pipeline([\n",
    "    (\"pre\", pre),\n",
    "    (\"model\", LogisticRegression(max_iter=1000, class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.25, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(classification_report(y_val, clf.predict(X_val), digits=3))\n",
    "\n",
    "# Probabilities for downstream use:\n",
    "val_proba = clf.predict_proba(X_val)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf869367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/er_pair_clf.joblib']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(clf, \"../models/er_pair_clf.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resolver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
